              QUANDARY INSTALLATION GUIDE


I.  Introduction and acknowledgements.

     QUANDARY (The spelling in all internal documentation
is QUANDRY due to linkage editor length limitations.)  is
a text-retrieval program developed at Auburn University to
provide an efficient method of searching the educational
abstracts prepared under government contract by E. R. I. C.,
the Educational Resources Information Clearinghouse.  QUANDARY
is a direct-access program designed to replace a tape-based
system previously in use.  Conversational support was added
to QUANDARY when TSO was installed at Auburn.
     Initial funding for the design of QUANDARY was provided by
the Foundations of Education Department of Auburn University.
Developmental funding was provided by the Auburn University
Computer Center.  The author particularly wishes to acknowledge
the contributions of Pat Graham (formerly of AUCC), Dr. James
Wilmoth (FED), and Dr. Ben Barnes (Director, AUCC).  Pat Graham
was especially helpful in his work on the UNPACK routine and in
providing numerous proofs of incorrectness of earlier versions
of QUANDARY.

II.  Status of QUANDARY.

     QUANDARY is currently in use at Auburn University and is
maintained for use at Auburn by the AUCC.  Copies of QUANDARY
are distributed by SHARE as part of the PL/I Project tape.
Installations receiving QUANDARY are of course responsible
for evaluating the suitability and correctness of QUANDARY.
The author, Auburn University, and SHARE, Inc. offer no
warranties and assume no liabilities for the use of QUANDARY.
Installations acquiring QUANDARY are requested to notify the
author at

          QUANDARY
          Auburn University Computer Center
          Auburn, AL 36830
          (Phone 205-826-4285)

     There is at least a reasonable chance that such users of
record will receive notification of bugs and future releases.
Please report any bugs or documentation errors to the address
given above.  Suggestions for improvements and modifications
are welcomed. (All such suggestions become the property of
Auburn University.)  Frankly, no action can be promised, but
at least some interest, or commiseration, or perhaps a little
guilt, might be forthcoming.

III.  Requirements for running QUANDARY.

     QUANDARY is currently running on a 370/158 under SVS with
3350 disk drives and TSO.  If QUANDARY is to be run on a 360,
some modifications to the assembler subroutines and the machine
code generator (CMPFLD) are probably needed to eliminate 370
instructions and byte-aligned operands.
     QUANDARY has run on both SVS and MVS.  There is no known
reason that it should not run on MFT or MVT, although this has
not been tested.  The BDAM and ISAM access methods are required.
Reports from VM installations are requested. (Note to VM users:
check the PL/I procedure TESTENV.)  QUANDARY provides special
support for conversational use when TSO is installed.
Searches can be run entirely at the terminal, or submitted
from QUANDARY to batch.  To effectively utilize the SUBMIT
capability, the SBMIT, CMPOPT, and TESTENV procedures will
probably need to be modified so that they will construct
JCL conforming to installation standards.
     QUANDARY has run, at different stages of development, on
3330 and 3350 drives, and is intended to be device-independent.
The programs which construct the QUANDARY datasets (the QUANDARY
"builders") issue DEVTYPE macro instructions.  QUANDARY proper is
unaware of device types.  Please report any device dependencies.
     Substantial direct access storage is required for the
datasets used by QUANDARY.  Auburn presently maintains the most
recent 120000 CIJE records and the most recent 55000 RIE records
on roughly 11000 tracks on 3350 drives.  (E.R.I.C. tapes come
in two series -- CIJE (Current Index to Journals in Education)
and RIE (Research in Education).)
     Since QUANDARY is written in Optimizer PL/I, it requires
the PL/I Optimizing Compiler Transient Library, an IBM Program
Product, which is available from IBM for a monthly fee.  If it
is desired to modify QUANDARY, the PL/I Optimizing Compiler and
the PL/I Resident Library Program Products are also required.
Conversion to PL/I(F) would probably prove difficult.

IV.  Design objectives, limitations, and constraints.

     Auburn faculty and students originally ran bibliographic
searches against a five-volume E.R.I.C. tape dataset.  The
development of QUANDARY was begun in order to provide comparable
facilities with less load on the system.  The Computer Center
offered to subsidize QUANDARY by providing one-half of a 3330
at no cost.
     QUANDARY was to take advantage of direct access storage;
it was to run efficiently and use auxiliary storage efficiently.
QUANDARY was to provide search capabilities comparable to the
existing tape-based system; it was to be easier to use for
education faculty and students with no programming experience.
The entire abstract field was to be printed.  Since updates
were received at three-month intervals, the efficiency of the
dataset builders was of little concern.
     Due to direct-access storage limitations, it was decided to
include only the ACCNUM (accession number), CHNUM (clearinghouse
number), DATE, TITLE, AUTHOR, DESCRIPTOR, IDENTIFIER, NOTE,
ISSUE, ABSTRACT, AVAIL (availability), JOURNAL, INST (institution),
and SPONSOR fields from the E.R.I.C. records.  The NOTE, ISSUE,
ABSTRACT, AVAIL, INST, and SPONSOR fields were stored in a
compacted form which could not be searched.  Since the printers
in use did not print lower case, all E.R.I.C. tapes were converted
to upper case.  It was decided to rebuild the files completely
every three months rather than write update programs.
     The records which had to be examined in a search were
limited by requiring that the user enter a "READ statement"
specifying set operations on E.R.I.C.-assigned keyword fields
("descriptors and identifiers").  Disk space did not permit
inverting other fields, which are examined in "field statements"
as the records satisfying the READ statement are read in.
(The author field was later inverted due to user demand.)
Since much of the CPU time used by the tape-based system was
consumed in interpretively examining fields, it was decided
that QUANDARY would generate machine code for field statements.
     Simplicity of use was of great importance since QUANDARY
would be used by education majors with no previous programming
experience.  The ability to use arbitrary logical expressions
involving several fields would rarely be needed but would
increase the complexity of QUANDARY statements.  It was decided
to limit field statements to expressions involving a single field.
Multiple field statements could be used to specify selection
criteria based on two or more fields.  READ statements were
allowed to intermix authors, descriptors, and identifiers.
In practice, almost all QUANDARY searches consist of a single READ
statement or a READ statement and a single field statement.  The
full logical capabilities of QUANDARY, limited though they are,
are seldom used.
     The grammar for expressions was defined to eliminate the
possibility of certain errors frequently made by beginning
programming students.  Operands were restricted to a limited
character set and made self-delimiting.  The grouping of
expressions by parentheses was prohibited; instead, two "or"
operators were introduced, '×' having higher priority than
'&' and ';' having lower priority.  Although the result may be
unsatisfying to those accustomed to the traditional productions,
QUANDARY expressions have proved easy to learn and quite adequate
in practice.
     The user guide is directed toward a novice computer user.
Whenever possible, examples are given in lieu of explicit rules.
Obscure rules never violated in practice ("A statement is limited
to 1200 characters.") are relegated to diagnostic messages. The
user guide still needs a lot of work.  Any assistance would be
appreciated.  (Aside to the observant:  Chapter I is indeed
missing.  It was never written.)
      A number of modifications to QUANDARY were made in support of
TSO.  In order to limit the overhead of online searches, an upper
bound (OPT.READLIM) of 500 was placed on the number of records
which would be examined by a READ statement under TSO.  Options
were added to build JCL to submit searches to batch.  An editing
facility was added to correct erroneous statements.  (Since most
statements written by students are short, the default option is
correction by statement reentry.  Thus editing statements need
not be taught to beginning users.)  A core limitation was placed
on QUANDARY so that it would run in a 192K TSO region. (QUANDARY
actually runs in 168K at Auburn with the PL/I transient library
routines in the PLPA.)

V.  Datasets

DSNAME          DSORG RECFM LRECL BLKSIZE TRACKS

CCP11.Q.ASM     PO    FB       80    1680      5
CCP11.Q.CLIST   PO    FB       80    1680      1
CCP11.Q.CNTL    PO    FB       80    1680      3
CCP11.Q.DATA    PO    FB       80    3120      1
CCP11.Q.LIST    PO    VBA     125     629     79
CCP11.Q.LOAD    PO    U      3600    3600     10
CCP11.Q.OBJ     PO    FB       80     400     30
CCP11.Q.PLI     PO    FB       80     400     31
CCP11.Q.TEXT    PO    VB      255    1680      4
CCP64.RETC      PS    VB     3600   13030     25
CCP64.RETR      PS    VB     3600   13030     72

VI.  Installation.

All partitioned datasets were unloaded with IEBCOPY.  The location
of the datasets on the PL/I project tape will be described (one
supposes) on documentation for the tape.  Since storage estimates
are never correct, add an extra 30% or so.  Ten directory blocks
should be adequate for all partitioned datasets.  Figures are in
3350 tracks.

     The datasets are used as follows:

CCP11.Q.ASM---------------source for assembler routines
CCP11.Q.CLIST(LINK)-------CLIST to link QUANDARY load module
CCP11.Q.CLIST(PLI)--------CLIST to compile and compress a member
CCP11.Q.CLIST(PLIFAST)----CLIST to compile a member of QUANDARY
CCP11.Q.CLIST(QNDINIT)----CLIST to initialize to run QUANDARY
CCP11.Q.CLIST(QNDRUN)-----CLIST to run QUANDARY
CCP11.Q.CNTL(BLDE)--------JCL to build ERIC direct file
CCP11.Q.CNTL(BLDO)--------JCL to build occurrence tape files
CCP11.Q.CNTL(BLDX)--------JCL to build MAP and INDX files
CCP11.Q.CNTL(DOC)---------introduction to the JCL for the builders
CCP11.Q.CNTL(LINK)--------batch link of QUANDARY
CCP11.Q.CNTL(QUANDARY)----QUANDARY procedure for SYS1.PROCLIB
CCP11.Q.CNTL(RUN)---------sample batch JCL to execute QUANDARY
CCP11.Q.DATA(LINK)--------linkage edit control cards
CCP11.Q.LIST--------------compilation listings for PL/I routines
CCP11.Q.LOAD(QUANDRY)-----QUANDARY load module (only one 'A')
CCP11.Q.OBJ---------------PL/I and ASM object modules for LINK
CCP11.Q.PLI---------------PL/I source and %INCLUDE declarations
CCP11.Q.TEXT(DOC)---------current documentation
CCP11.Q.TEXT(HANDOUT)-----short version of user guide (upper/lower)
CCP11.Q.TEXT(USRGUIDE)----user guide (upper/lower case)
CCP64.RETC----------------500 CIJE records for test files
CCP64.RETR----------------500 RIE records for test files


     The JCL in use at Auburn has been shipped in the dataset
CCP11.Q.CNTL.  Some modifications will be needed to conform to
local installation standards.  The comments included in the JCL
for each job should be read before attempting any modifications.
JOBPARM time values are in seconds (ss) or minutes and seconds
(mmss) of CPU time on a 158 for a file of 175000 records.
     The steps in installing QUANDARY, building the sample files,
and testing the system are listed below.  More complete information
will be found in the JCL for each job mentioned.

1.   Restore the QUANDARY datasets from the PL/I Project tape
according to the instructions shipped with the tape.  The LIST
dataset is not used.  The CLIST dataset is needed only for TSO.
2.   Read, modify, and run CCP11.Q.CNTL(BLDE).  BLDE reads the
sample E.R.I.C. datasets (CCP64.RETC and CCP64.RETR) and
builds the regional (BDAM) file CCP11.Q.E.
3.   Read, modify, and run CCP11.Q.CNTL(BLDO).  BLDO reads
CCP11.Q.E to find potential access keys -- major descriptors,
minor descriptors, major identifiers, minor identifiers, and
authors.  For each occurrence of a key, a record containing
the key and the disk address where it was found is written to
tape.
4.   Read, modify, and run CCP11.Q.CNTL(BLDX).  BLDX reads the
tapes built by BLDO and builds two direct-access datasets:  The
regional map file (CCP11.Q.M) contains lists of all occurrences
of a key.  The ISAM index file (CCP11.Q.X) contains the keys
themselves and a pointer to the beginning of their occurrence
list in the map file.
5.   The datasets which have been created must now be renamed
and recataloged to use the JCL shipped.  Change CCP11.Q.E to
CCP64.E, CCP11.Q.M to CCP64.M, CCP11.Q.X to CCP64.X, and
CCP11.Q.LOAD to CCP64.QUANLIB.
6.   Copy CCP11.Q.CNTL(QUANDARY) to SYS1.PROCLIB.
7.   Read and modify the clists in CCP11.Q.CLIST(QNDINIT) and
CCP11.Q.CLIST(QNDRUN).  Suggestions for modifying CLISTS are
found in CCP11.Q.CLIST(DOC).  Copy the modified members into
the installation CLIST dataset.
8.   Read, modify, and run the test program CCP11.Q.CNTL(RUN).
9.   Try a TSO session.  (Reading CCP11.Q.TEXT(USRGUIDE) may be
helpful.)  Suggested input is:

     qndinit
     qndrun
     read *algor/go/end/
