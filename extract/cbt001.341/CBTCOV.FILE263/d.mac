.he ABE, T. Smith, Appendix D

Appendix D - Relational Query Language (RQL)                           @









                       A B E  E d i t o r


                         T .  S m i t h

                       A P P E N D I X  D

        R E L A T I O N A L   Q U E R Y   L A N G U A G E

                           ( R Q L )







INTRODUCTION, APPENDIX D                                               @

This appendix describes the Relational Query Language (RQL) built into
the ABE editor. RQL is based on both the IBM SQL/DS relational database
query language, and on SAS (Statistical Analysis System) (SAS is a
trademark of the SAS Institute, Inc.). In fact, many of the examples in
this appendix were copied verbatim from the manuals on SQL/DS and SAS.

Basically, RQL currently includes the USE, SELECT, ORDER, UPDATE,
UPDATEC, ENTER, REMOVE, and LOCATE subcommands:

    The USE subcommand is used to define a database view of a data
    set. That is, the name, position, and length of all fields
    defined over a data set.

    The SELECT subcommand is used to perform queries, and its syntax
    is very similar to the SELECT statement in IBM's Structured Query
    Language (SQL).

    ORDER is used to sort the data.

    UPDATE is used to modify and add fields in a dataset.

    UPDATEC differs from UPDATE in that it updates only the current
    record, whereas UPDATE updates all records in the dataset.

    ENTER is used for bulk data entry.

    LOCATE is used to locate records satisfying a given expression.

    REMOVE is used to delete or remove records satisfying a given
    expression.


USE SUBCOMMAND - A BRIEF INTRODUCTION                                  @


As already indicated, the USE subcommand is used to define the name,
position, and length of all fields defined over a data set.  This
section will provide enough information on how that is done to carry
on with the discussion of the RQL language in general. A later
section titled "THE USE SUBCOMMAND - MORE DETAILED INFORMATION"
goes into greater depth.

Suppose you have a data set called INVENTRY being edited:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      001 207    GEAR          75
      002 209    CAM           50
      (lines omitted for brevity)

You would like to define three fields, PARTNO, DESCRIPT, and
QONHAND over the three columns.  The simplest way to do this is
to first enter the subcommand "use ×a".  This will define the
field named A to encompass the entire record.  Such a field has
no useful purpose; the aim is to get some sort of database view
defined so that ABE will add what is called the DBD line to the
display:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      DBD ×A
      001 207    GEAR          75
      002 209    CAM           50
      (lines omitted for brevity)

Now you can move the cursor down to the DBD line and alter its
contents to the desired values, using the first record as a guide
to where each field is to end and the next one is to begin:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      DBD ×partno×descript $×qonhand×
      001 207    GEAR          75
      002 209    CAM           50
      (lines omitted for brevity)

You place a vertical bar in the starting column of each new field,
followed by the field name, optionally followed by a space and a
dollar sign ($) if the field is character (as opposed to pure
numerics).  Once the DBD is defined, you can use the field names in
subsequent SELECT subcommands:


                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      select * where qonhand>999 to lots                    ×INVENTRY
      DBD ×PARTNO×DESCRIPT $×QONHAND×
      001 207    GEAR          75
      002 209    CAM           50
      003 221    BOLT         650
      004 222    BOLT        1250
      005 231    NUT          700
      006 232    NUT         1100
      007 241    WASHER      6000
      008 285    WHEEL        350
      009 295    BELT          85

the result of the above query would be the following:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      ==>                                                   ×LOTS
      DBD ×PARTNO×DESCRIPT $×QONHAND×
      001 222    BOLT       1250
      002 232    NUT        1100
      003 241    WASHER     6000

You may already be asking yourself, how would the field names have
been defined if the data in the records weren't conveniently
spread out?  In other words, suppose INVENTRY had looked like the
following:

                  1         2         3
         123456789012345678901234567890
                             ×INVENTRY×
     DBD ×A
     001 207 GEAR             75
     002 209 CAM              50
     (lines omitted for brevity)

Now there isn't enough room to print the first field name, PARTNO,
and get a vertical bar in the starting position of the DESCRIPT
field which comes next.

the answer is to alter the DBD line as follows:

                  1         2         3
         123456789012345678901234567890
                             ×INVENTRY×
     DBD ×z  ×descript $   ×z   ×
     001 207 GEAR             75
     002 209 CAM              50
     (lines omitted for brevity)

The field name Z has special significance; when ABE sees it in
the altered DBD line, it will clear the screen and prompt you
for the real field name.  In the above case, you would be
prompted for the first and the third field names, and you could
then enter SUPPNO, and QONHAND, respectively.

Of course, there still won't be room for ABE to print these field
names on the DBD line.  Instead, it will print "Z" for the field
name.  If you subsequently forget what names you used, enter the
subcommand "use list".  ABE will temporarily clear the screen and
display information, including names, for all fields defined
over the data set.




SELECT SUBCOMMAND - DATABASE QUERIES                                   @

One of the simplest uses of SELECT is for the rearrangement of
data in the records.  For example, suppose the following data
set, previously described were being edited.  You could reverse
the order of fields in each record by the SELECT subcommand
shown:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      select qonhand,descript,partno                        ×INVENTRY
      DBD ×PARTNO×DESCRIPT $×QONHAND×
      001 207    GEAR       75
      002 209    CAM        50
      (lines omitted for brevity)

the results would be the following:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      DBD ×PARTNO×DESCRIPT $×QONHAND×
      001 207    GEAR       75
      002 209    CAM        50
      (lines omitted for brevity)
      ==>
      DBD ×QONHAND×DESCRIPT $×PARTNO×
      001    75   GEAR       207
      002    50   CAM        209
      (lines omitted for brevity)

The select command above created a new virtual data set containing
copies of all the records from the first data set with fields
reversed.

ELIMINATING VIEWS                                                      @

You can eliminate the current view of the data set, and eliminate
the DBD line from the display simply by entering the subcommand
"use ×".  The results for the INVENTRY data set previously shown
would be as follows:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      001 207    GEAR       75
      002 209    CAM        50
      (lines omitted for brevity)

SUPPLYING LITERALS IN THE SELECT LIST                                  @

Note that the list of fields to be selected (called the select list)
on a SELECT subcommand may also contain quoted strings in addition
to field names.  In the following example, a list of 8-character
names are to be surrounded by parentheses:


                  1         2         3
         123456789012345678901234567890
     select '(',mem,')'       ×MEMBERS×
     DBD ×MEM $  ×
     001 AU109207
     002 AU109227
     003 AU109228
     004 AU109229
     005 AU109545
     006 AU109546

the results would be the following:

                  1         2         3
         123456789012345678901234567890
     ==>
     DBD ××MEM $  ××
     001 (AU109207)
     002 (AU109227)
     003 (AU109228)
     004 (AU109229)
     005 (AU109545)
     006 (AU109546)



COMBINING DATASETS USING SELECT - ALL COMBINATIONS                     @

Another useful function with SELECT is combining data sets.  This
first example will illustrate combining all possible combinations
of the fields in three data sets.  Suppose you had data sets a, b,
and c as shown below, and entered the SELECT subcommand as shown
(see the third command line):

                    1         2         3
           1234567890123456789012345678901234
                                              ×A×
       DBD ×FA×
     00001 AA1
     00002 AA2
     ====>                                    ×B×
       DBD ×FB×
     00001 BB1
     00002 BB2
     ====> select * from a,b,c to d           ×C×
       DBD ×FC×
     00001 CC1
     00002 CC2

the results would be as follows:

                    1         2         3
           1234567890123456789012345678901234
                                              ×A×
       DBD ×FA×
     00001 AA1
     00002 AA2
     ====>                                    ×B×
       DBD ×FB×
     00001 BB1
     00002 BB2
     ====>                                    ×C×
       DBD ×FC×
     00001 CC1
     00002 CC2
     ====>                                    ×D×
       DBD ×FA×FB×FC×
     00001 AA1BB1CC1
     00002 AA1BB1CC2
     00003 AA1BB2CC1
     00004 AA1BB2CC2
     00005 AA2BB1CC1
     00006 AA2BB1CC2
     00007 AA2BB2CC1
     00008 AA2BB2CC2

As you can see, multiple data sets can be specified in the FROM
clause.  The logic used in combining records is very similar to
that used in the RELJOIN subcommand, except that it is extended
to multiple input data sets.  The logic is as follows:

  0.  Given a set of data sets D1 thru Dn, define a LIFO stack
      (Last-In-First-Out stack, also known as a push-pop stack)
      for variable x.  A reference to variable x will receive the
      value on the top of the stack.

  1.  Push 0 onto the stack for variable x.

  2.  Push x+1 onto the stack.

  3.  If top of stack is greater than the maximum number Dn,
      then goto step 4; else goto step 6.

  4.  Create a new record in the output data set from the fields
      specified in the select list.  If a field name is ambiguous,
      that is two or more from-datasets have that field, and the
      field name wasn't qualified (name.field_name) in the select
      list, choose the field value from the first from-dataset
      encountered in the from list.

  5.  Pop the top element off stack.  If top of stack now equals 0,
      then goto 9; else goto 7.

  6.  Set the "current record pointer" for data set Dx in front of
      the first record in the data set.

  7.  Get the next record in data set Dx.  If no more records,
      then goto 5; else goto 2.

  9.  FINIS.

COMPUTING NEW VARIABLES                                                @

Each of the items in the select-list of the SELECT subcommand can also
be an expression.  For example, suppose you have a data set in which
each record contains the sales figures for each month of a particular
year, and you want to find the total sales for the first six months
of each year.  This can be done as follows:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      SELECT YEAR,JAN+FEB+MAR+APR+MAY+JUN TO TOTALS FROM SALES ×SALES
      DBD ×YEAR×JAN×FEB×MAR×APR×MAY×JUN×JUL×AUG×SEP×OCT×NOV×DEC
      001 1981 230 114 175 184 567 905 230 174 51  7   300 99
      002 1982 475 23  4   0   58  97  870 341 500 8   299 1
      003 1983 1   2   3   4   5   6   7   8   9   10  11  12

the results would be as follows:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                      ×SALES
      DBD ×YEAR×JAN×FEB×MAR×APR×MAY×JUN×JUL×AUG×SEP×OCT×NOV×DEC
      001 1981 230 114 175 184 567 905 230 174 51  7   300 99
      002 1982 475 23  4   0   58  97  870 341 500 8   299 1
      003 1983 1   2   3   4   5   6   7   8   9   10  11  12
      ==>                                                     ×TOTALS
      DBD ×YEAR×EXP1           ×
      001 1981 2175
      002 1982 657
      003 1983 21

The expressions in the select-list can be more complicated, and
can include function references for such things as SIN, COS, TAN,
SQRT, etc.  In fact, any expression which may used on the CALC
subcommand can also be used as a select-list element (See
documentation on the CALC subcommand in Part II of this manual).



MISSING VALUES AND INVALID NUMERIC DATA                                @

The manner in which ABE handles missing values and invalid numeric
data is very similar to the way SAS does it.  Internally, missing
values are stored as floating point numbers with the hexadecimal
representation x'80000000'.  Later on in this manual, you will see
that fields can also be maintained in packed decimal, integer binary,
and floating point.  In these cases, missing values are as follows:

  packed decimal - -9999...9 for maximum length of field.
  integer (fixed bin(31)): -2147483648
  integer (fixed bin(15)): -32768
  float: unspec=x'80000000'

A field in a record which contains
either all blanks, or simply a period (.), is considered to contain
a missing value.  A numeric field which contains non-numeric data
will be treated as though it contained a missing value for
purposes of comparison and arithmetic operations.

Any arithmetic operation involving a field containing a missing value
has a missing value for a result. For character field comparisons,
missing values compare as blanks.  For arithmetic comparisons,
missing values compare equal to minus infinity.

Note that the name MISSING is special, and represents a missing
value.  The statement "select * where qonhand=missing" for example,
ways to select all records where field qonhand contains a missing
value.

SUBSETTING RECORDS                                                     @

You have a data set containing records describing males and females,
with a variable in each record indicating sex, and you would like
to obtain a data set just containing information on females:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      select * from both where sex='f' to females               ×BOTH
      DBD ×NAME $ ×YEAR×GPA ×SEX $×
      001 JIM     2    3.3  M
      002 ANN     4    3.8  F
      003 SUE     1    2.3  F
      004 TOM     3    3.0  M

the results would be as follows:

     ===>                                                    ×FEMALES
      DBD ×NAME $ ×YEAR×GPA ×SEX $×
      001 ANN     4    3.8  F
      002 SUE     1    2.3  F

CONCATENATING DATA SETS                                                @

You have two or more data sets you would like to combine into a
single data set:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                       ×Y1978
      DBD ×QUARTER×SALES
      001 1       20800
      002 2       19977
      003 3       18423
      004 4       24778
      ==> select * from y1978,y1979 to both set                ×Y1979
      DBD ×QUARTER×SALES
      001 1       27800
      002 2       24005
      003 3       25120
      004 4       30802

the results would be the following:

      ==>                                                       ×BOTH
      DBD ×QUARTER×SALES
      001 1       20800
      002 2       19977
      003 3       18423
      004 4       24778
      005 1       27800
      006 2       24005
      007 3       25120
      008 4       30802

INTERLEAVING DATA SETS                                                 @

You have two data sets, one for each department in your company.
each data set is sorted by the same variable, LASTNAME.  You want
to merge the two data sets, ending with one data set sorted by
LASTNAME, but with interleaved records from the two data sets:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                       ×DEPT1
      DBD ×LASTNAME $×BIRTHYR×
      001 ADAMS      1948
      002 BENSON     1954
      003 DAVIS      1932
      004 WHITE      1958
      ==> select * from dept1,dept2 to allempl set by lastname ×DEPT2
      DBD ×LASTNAME $×BIRTHYR×
      001 ANDREWS    1941
      002 BLACK      1950
      003 LITTLE     1951
      004 WEST       1945

the results would be the following:

      ==>                                                    ×ALLEMPL
      DBD ×LASTNAME $×BIRTHYR×
      001 ADAMS      1948
      002 ANDREWS    1941
      003 BENSON     1954
      004 BLACK      1950
      005 DAVIS      1932
      006 LITTLE     1951
      007 WEST       1945
      008 WHITE      1958

MATCHING RECORDS, ONE-TO-ONE                                           @

You have two data sets, each with the same number of records, each
with different variables.  You want to merge the first record of one
data set with the first record of the other data set; the second
record with the second record; and so on.  The new data set will
contain the same number of records as each of the input data sets,
but the number of variables will equal the total of the unique
variable names in each of the input data sets:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                     ×FEMALES
      DBD ×GIRL $ ×
      001 ANN
      002 CAROL
      003 MARY
      004 SUSAN
      ==> select * from females,males to match merge         ×MALES
      DBD ×BOY  $ ×
      001 BOB
      002 JIM
      003 JOHN
      004 MARK

the results would be the following:

      ==>                                                    ×MATCH
      DBD ×GIRL $ ×BOY  $ ×
      001 ANN     BOB
      002 CAROL   JIM
      003 MARY    JOHN
      004 SUSAN   MARK

MATCHING RECORDS HAVING A COMMON VARIABLE                              @

You have a data set containing a master file and another data set
containing a transaction file of updates to the master.  There may
be several transactions for each master observation.  Both data sets
contain the same variables, but the transaction data set probably
contains many missing values for variables not being updated.
both data sets are sorted by the identifying variable:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                     ×OLDMSTR
      DBD ×ID  ×NAME $  ×DEPT×SALARY
      001 5430 BLACK,AR 813  15820
      002 9684 AAB,JK   811  10765
      003 9765 WHITE,KC 900  20650
      ==>select * from oldmstr,trans update by id            ×TRANS
      DBD ×ID  ×NAME $  ×DEPT×SALARY
      001 9684          813
      002 9684               12600
      003 9765               22500
      004 9970 CAAN,JR  815  15000

the result would be the following

      ==>
      DBD ×ID  ×NAME $  ×DEPT×SALARY
      001 5430 BLACK,AR 813  15820
      002 9684 AAB,JK   813  12600
      003 9765 WHITE,KC 900  22500
      004 9970 CAAN,JR  815  15000

TABLE LOOKUP                                                           @

You have one data set that is your table: it contains an identifier
variable and corresponding descriptions.  You want to merge the
descriptions with another data set that contains only the identifier
variable:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                       ×TABLE
      DBD ×NUMBER×DESCRIPT $×
      001 100    NAILS
      002 200    HAMMERS
      003 250    BOLTS
      004 300    SAWS
      ==> select * from data,table merge by number             ×DATA
      DBD ×STORE $×NUMBER×SALES×
      001 A       100    2500
      002 B       100    3570
      003 A       200     750
      004 A       250    1000
      005 C       250     980
      006 C       300    1576

the results would be the following:

      ==>
      DBD ×STORE $×NUMBER×SALES×DESCRIPT $×
      001 A       100    2500  NAILS
      002 B       100    3570  NAILS
      003 A       200     750  HAMMERS
      004 A       250    1000  BOLTS
      005 C       250     980  BOLTS
      006 C       300    1576  SAWS


SAMPLE DATA SETS FOR FURTHER EXAMPLES                                  @

Following are listings for three sample data sets that will be used
in many of the examples in future pages:


                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      DBD ×PARTNO×DESCRIPT $ ×QONHAND×
      001 207    GEAR          75
      002 209    CAM           50
      003 221    BOLT         650
      004 222    BOLT        1250
      005 231    NUT          700
      006 232    NUT         1100
      007 241    WASHER      6000
      008 285    WHEEL        350
      009 295    BELT          85
      ==>                                                   ×SUPPLIER
      DBD ×SUPPNO×NAME $         ×ADDRESS $                       ×
      001 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      002 52     VESUVIUS, INC.  312 ANCIENT BLVD., POMPEII NY
      003 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC
      004 54     TITANIC PARTS   32 LARGE ST., BIGTOWN TX
      005 57     EAGLE HARDWARE  64 TRANQUILITY PLACE, APOLLO MN
      006 61     SKY PARTS       128 ORBIT BLVD., SIDNEY AUSTRALIA
      007 64     KNIGHT LTD.     256 ARTHUR COURT, CAMELOT ENGLAND
      ==>                                                   ×QUOTATNS
      DBD ×SUPPNO×PARTNO×PRICE×DELIV×QONORDER×
      001 51     221      .30 10    50
      002 51     231      .10 10    0
      003 53     222      .25 15    0
      004 53     232     .10  15    200
      005 53     241      .08 15    0
      006 54     209    18.00 21    0
      007 54     221      .10 30    150
      008 54     231      .04 30    200
      009 54     241      .02 30    200
      010 57     285    21.00 14    0
      011 57     295     8.50 21    24
      012 61     221      .20 21    0
      013 61     222      .20 21    200
      014 61     241      .05 21    0
      015 64     207    29.00 14    20
      016 64     209    19.50 7     7


WHERE-CLAUSE: SPECIFYING SELECTION CRITERIA                            @

The following query subcommand selects all columns from the INVENTRY
table where the description field contains BOLT:

     select * from inventry where descript='bolt'

the results would be as follows:

      ==>
      DBD ×PARTNO×DESCRIPT $×QONHAND
      001 221    BOLT       650
      002 222    BOLT       1250

Note that the WHERE clause can be a more complex expression as in
the case where the rows of the QUOTATNS table for part number 221
that have some quantity on order are to be selected:

     select * from quotatns where partno=221 & qonorder>0

the results would be:

      ==>
      DBD ×SUPPNO×PARTNO×PRICE×DELIV×QONORDER×
      001 51     221      .30 10    50
      002 54     221      .10 30    150

WHERE-CLAUSE: THE LIKE KEYWORD                                         @

Rows can be selected that contain a particular combination of
characters in columns containing character type data.  For instance,
you might want to select the name and address of those suppliers that
are located in New York (NY) from the SUPPLIER table:

  select name,address +
    from supplier +
    where address like '%ny%'

The LIKE function uses two character to mean special things.  A
% character represents any string of zero or more characters.  An _
character represents any single character.  Thus, the following
command selects those rows in the INVENTRY table containing a
description that is four characters long and starts with the letter b:

  select * +
    from inventry +
    where descript like 'b___'

WHERE-CLAUSE: THE IN KEYWORD                                           @

All rows can be selected in which the value of a specified field
is one of a list of values.  For instance, given the SUPPLIER
database below, and the indicated SELECT subcommand:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      select * where suppno in (51,53)                      ×SUPPLIER
      DBD ×SUPPNO×NAME $         ×ADDRESS $                       ×
      001 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      002 52     VESUVIUS, INC.  312 ANCIENT BLVD., POMPEII NY
      003 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC
      004 54     TITANIC PARTS   32 LARGE ST., BIGTOWN TX
      005 57     EAGLE HARDWARE  64 TRANQUILITY PLACE, APOLLO MN
      006 61     SKY PARTS       128 ORBIT BLVD., SIDNEY AUSTRALIA
      007 64     KNIGHT LTD.     256 ARTHUR COURT, CAMELOT ENGLAND


the result would be:

      ==>                                                   ×T0000000
      DBD ×SUPPNO×NAME $         ×ADDRESS $                       ×
      001 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      003 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC

STORING DATABASE VIEWS WITH THE DATASET                                @

When you use the USE subcommand to define fields over a data set,
this is called defining a view of the data.  You may perhaps want
to store a view along with the data records when the dataset is
saved, and use that same view when the dataset is edited again.
such a facility is supported through the "USE IN" and "USE OUT"
subcommands.

Suppose the "USE OUT" subcommand is entered for the following
data set:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      use out                                               ×INVENTRY
      DBD ×PARTNO×DESCRIPT $ ×QONHAND×
      001 207    GEAR          75
      002 209    CAM           50
      (lines omitted for brevity)

the result would be the following:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      PF                                                    ×INVENTRY
      001 DATA INVENTRY;
      002 INPUT  PARTNO   001-007 DESCRIPT $ 008-018 QONHAND  019-026;
      003 CARDS;
      004 207    GEAR          75
      005 209    CAM           50
      (lines omitted for brevity)

As you can see, the view has been eliminated, and instead 3 records
have been added to the front of the data set containing the view
definition (If you are familiar with SAS, you will recognize the
format).  If the data set were subsequently saved, these records
could of course be saved also.

Given any data set with a set of records in the front as just
described, the subcommand "use in" will reinstate the view, as in
the following example:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      use in                                                ×SUPPLIER
      001 DATA SUPPLIER;
      002 INPUT  SUPPNO 001-007 NAME $ 008-023 ADDRESS $ 024-056;
      003 CARDS;
      004 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      005 52     VESUVIUS, INC.  312 ANCIENT BLVD., POMPEII NY
      006 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC
      007 54     TITANIC PARTS   32 LARGE ST., BIGTOWN TX
      008 57     EAGLE HARDWARE  64 TRANQUILITY PLACE, APOLLO MN
      009 61     SKY PARTS       128 ORBIT BLVD., SIDNEY AUSTRALIA
      010 64     KNIGHT LTD.     256 ARTHUR COURT, CAMELOT ENGLAND

the results:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

                                                            ×SUPPLIER
      DBD ×SUPPNO×NAME $         ×ADDRESS $                       ×
      001 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      002 52     VESUVIUS, INC.  312 ANCIENT BLVD., POMPEII NY
      003 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC
      004 54     TITANIC PARTS   32 LARGE ST., BIGTOWN TX
      005 57     EAGLE HARDWARE  64 TRANQUILITY PLACE, APOLLO MN
      006 61     SKY PARTS       128 ORBIT BLVD., SIDNEY AUSTRALIA
      007 64     KNIGHT LTD.     256 ARTHUR COURT, CAMELOT ENGLAND

As you can see above, through the "use in" and "use out" subcommands
tou can retain and reuse a view of a dataset.  If the low-level
qualifier of the dsname for a dataset being edited is ".DB" (as in
X75826.INVENTRY.DB), a temporary "use in" subcommand will be issued
automatically for you when you enter ABE to edit the data set, and a
"use out" subcommand is issued automatically whenever you save the
data set.


SELECTING DISTINCT VALUES                                              @

Given that the QUOTATNS file is in sequence by the PARTNO field,
the following SELECT subcommand will select only the distinct,
or unique, part numbers:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      select distinct partno                                ×QUOTATNS
      DBD ×SUPPNO×PARTNO×PRICE×DELIV×QONORDER×
      001 64     207    29.00 14    20
      002 54     209    18.00 21    0
      003 64     209    19.50 7     7
      004 51     221      .30 10    50
      005 54     221      .10 30    150
      006 61     221      .20 21    0
      007 61     222      .20 21    200
      008 53     222      .25 15    0
      009 51     231      .10 10    0
      010 54     231      .04 30    200
      011 53     232     .10  15    200
      012 54     241      .02 30    200
      013 53     241      .08 15    0
      014 61     241      .05 21    0
      015 57     285    21.00 14    0
      016 57     295     8.50 21    24

following is the result:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      ==>
      DBD ×PARTNO×
      001 207
      002 209
      003 221
      004 222
      005 231
      006 232
      007 241
      008 285
      009 295

So far, SELECT DISTINCT seems to work just like it does in SQL/DS,
but there is a significant difference;  The DISTINCT option in
SQL/DS doesn't assume any order for the records, but ABE does.
ABE won't give you an error message if the file is not in
order by the field to which the DISTINCT option applies, but
it will produce results like the following:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      select distinct partno                                ×QUOTATNS
      DBD ×SUPPNO×PARTNO×PRICE×DELIV×QONORDER×
      001 51     221      .30 10    50
      002 51     231      .10 10    0
      003 53     222      .25 15    0
      004 53     232     .10  15    200
      005 53     241      .08 15    0
      006 54     209    18.00 21    0
      007 54     221      .10 30    150
      008 54     231      .04 30    200
      009 54     241      .02 30    200
      010 57     285    21.00 14    0
      011 57     295     8.50 21    24
      012 61     221      .20 21    0
      013 61     222      .20 21    200
      014 61     241      .05 21    0
      015 64     207    29.00 14    20
      016 64     209    19.50 7     7

the results:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      ==>
      DBD ×PARTNO×
      001 221
      002 231
      003 222
      004 232
      005 241
      006 209
      007 221
      008 231
      009 241
      010 285
      011 295
      012 221
      013 222
      014 241
      015 207
      016 209

SORTING RECORDS - ORDER-BY SUBCOMMAND                                  @

You can order records in a data set with the ORDER subcommand.  This
is equivalent to using the SORTQ subcommand, except you use field
names instead of record offsets and lengths.  For example, to
get the QUOTATNS file previously shown in order by field PARTNO,
one could enter the subcommand "order by partno".  To get it in
descending sequence by PRICE within ascending sequence by DELIV,
enter the subcommand "order by deliv,price desc".  The results
would be as follows:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

                                                            ×QUOTATNS
      DBD ×SUPPNO×PARTNO×PRICE×DELIV×QONORDER×
      001 64     209    19.50 7     7
      002 51     221      .30 10    50
      003 51     231      .10 10    0
      004 64     207    29.00 14    20
      005 57     285    21.00 14    0
      006 53     222      .25 15    0
      007 53     232     .10  15    200
      008 53     241      .08 15    0
      009 54     209    18.00 21    0
      010 57     295     8.50 21    24
      011 61     222      .20 21    200
      012 61     221      .20 21    0
      013 61     241      .05 21    0
      014 54     221      .10 30    150
      015 54     231      .04 30    200
      016 54     241      .02 30    200

It is important to note that numeric fields are sorted according
to their numeric value and not their character representations.
thus, line with sequence number 7 would sort  differently if PRICE
were defined as character.

SORTING RECORDS - ORDER-BY CLAUSE                                      @

In addition to there being an ORDER subcommand, there is also an
ORDER-BY clause you can optionally use on the SELECT subcommand. For
example, to make a copy of called SAMPLE of QUOTATNS and sort SAMPLE
into descending sequence by PRICE within ascending sequence by DELIV,
enter the subcommand "select * to sample order by deliv,price desc".

NESTED SELECT SUBCOMMMANDS                                             @

A previous example showed what would happen if you use the DISTINCT
keyword for a data set which was not in sequence by the specified
variable.  One solution already shown was to sort the original
data set using the ORDER subcommand before issuing the SELECT
subcommand.  Another solution is to use a nested SELECT subcommand.

In the previous example, the goal was to find out which part numbers
are listed in the QUOTATNS file.  This can be done regardless of
the order of the original file with the single subcommand -

  select distinct partno +
    from(select partno from quotatns order by partno)

The above subcommand will first define a temporary virtual data
set into which all the part numbers from QUOTATNS will be selected.
this temporary file will be sorted into sequence by part number,
and then all distinct part numbers in this temporary file will
be copied to the final resulting virtual data set.  Finally, an
"end nosave" subcommand will be issued for the temporary virtual
data set.

The subcommand could also have been written -

  select distinct partno +
    from(select partno from quotatns order by partno TO PARTLIST)

The upper case letters in the above subcommand were used merely
to highlight the TO-clause which was added.  If a TO-clause is
used in a nested SELECT, the virtual data set created to contain
the results will not be temporary, and an "end nosave" subcommand
will not be issued for it at the end of processing.

SUMMARY STATISTICS - SUM, AVG, MIN, MAX, STD, COUNT                    @

Five builtin functions can be applied to data retrieved via a
SELECT subcommand.  They are -

  AVG   - finds the average value
  SUM   - finds the total value
  MIN   - finds the minimum value
  MAX   - finds the maximum value
  STD   - finds the standard deviation
  COUNT - finds the number of values.

For example, the following provides the average quoted price and
total quantity on order for part number 221:

  select avg(price),sum(qonorder) to sample +
    from(select * from quotatns where partno=221)

the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                            ×SAMPLE
      DBD ×EXP1         ×EXP2       ×
      001 .2            200

COUNT can be used to count the number of rows selected or, it can
be used to count the number of distinct values in a particular
column of the rows selected.  For example, the following query
counts how many rows for part number 221 are in the QUOTATNS
table:

  select count from quotatns where partno=221

the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×EXP1
      001 3

and this query counts how many distinct (different) part numbers
are in the QUOTATNS table:

  select count from(select distinct partno from( +
    select partno order by partno))

the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×EXP1
      001 9

BLANKET SUMMARY STATISTICS                                             @

A select statement such as "select sum" is special.  It tells ABE to
apply the given statistical function to every numeric field defined
over the data set.  If "select sum" were applied to the QUOTATNS
file, the results would be as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×SUPPNO×PARTNO×PRICE×DELIV×QONORDER
      001 902    3729   97.44 295   1051

JOINING A DATA SET WITH ITSELF                                         @

You can temporarily assign shorter labels in SELECT subcommand to
reduce the wordiness, and also to provide some additional query
flexibility.  For example, assume you want to know the combined
price of nut 231 and bolt 221 from each of the suppliers that sell
both parts.  (In the example which follows, notice the use of
shorthand references "qa" and "qb"):

  select suppno,qa.price+qb.price +
    from quotatns-qa, quotatns-qb +
    where qa.suppno=qb.suppno &   +
          qa.partno=231 &         +
          qb.partno=221
    order by exp1

the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×SUPPNO      ×EXP1       ×
      001 54           .14
      002 51           .4


GROUP BY CLAUSE - SUBGROUPING SUMMARY STATISTICS                       @

The GROUP BY clause can reduce the necessary number of queries.  For
example, to find the average price of each part in the QUOTATNS
table, issue:

  select partno,avg(price) +
    from (select partno,price +
      from quotatns order by partno) +
    group by partno

the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×PARTNO×EXP1       ×
      001 207    29
      002 209    18.75
      003 221    .2
      004 222    .225
      005 231    .07
      006 232    .1
      007 241    .05
      008 285    21
      009 295    8.5

Note that ABE has one restriction on the GROUP BY clause SQL/DS does
not have.  Namely, all references in the GROUP BY clause must also
appear in the select list.  For example, "select count group by name"
is not a legal statement, whereas "select name,count group by name"
is.

MORE ON NESTED SELECTS                                                 @

The previous example illustrated a nested query to obtain a copy of
the quotatns file in sequence by partno. A further level of nesting
finds the average price for those parts in the QUOTATNS table that
are based on more than one quote:

  select * from( +
    select partno,avg(price),count +
      from (select partno,price +
        from quotatns order by partno) +
      group by partno) +
    where exp2>1

Note the reference to field EXP2.  Any select-list element which is
either an expression or function reference will have its field name
generated in the form "EXPn" where n is 1, 2, ...

the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×PARTNO×EXP1          ×EXP2   ×
      001 209    18.75          2
      002 221    .2             3
      003 222    .225           2
      004 231    .07            2
      005 241    .05            3

Suppose you want to know the quotations for those parts that have a
price less than the average price for that part:

      select suppno,partno,price,exp1 +
       merge by partno +
       from +
        (select * from quotatns order by partno to q1), +
        (select partno,avg(price) from q1 group by partno) +
       where price < exp1

the results would be the following:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                  ×
      DBD ×SUPPNO×PARTNO×PRICE×EXP1       ×
      001 54     209    18.00 18.75
      002 54     221      .10 .2
      003 61     222      .20 .225
      004 54     231      .04 .07
      005 54     241      .02 .05

IMPORTANT!!! - SPECIAL USE OF Qdddddd DATASET SYMBOLIC NAMES           @

Note the use of the name Q1 in the to-clause in the previous
example.  Symbolic data set names of the form "Qddd", where ddd
is 0 to 8 numeric digits are treated specially by all of the
SQL subcommands;  WHEN THE SUBCOMMAND COMPLETES, AN "END N"
SUBCOMMAND IS SCHEDULED AUTOMATICALLY FOR ALL DATA SETS CURRENTLY
BEING EDITED WITH SYMBOLIC NAMES OF THIS FORM.

Note also that you should not use more than 6 numeric digits
following the Q in your symbolic names.  The SELECT subcommand
creates its own temporary datasets internally with names of the
form "Qddddddd", where ddddddd is always 7 digits.

RESTRICTIONS ON COMMAND LENGTH                                         @

Currently, there is the restriction that no ABE subcommand can
exceed 1024 characters in length.  Until recently, this restriction
was 256 characters.
Thus, in order to look at the
parts inventry for parts that were supplied by the supplier whose
name is 'ATLANTIS CO.', several queries were required:

    select * to t1 from inventry order by partno
    select distinct partno to t2 from +
      (select partno order by partno +
      where t3.suppno=quotatns.suppno from quotatns, +
      (select suppno to t3 from supplier where name='atlantis co.'))
    select * to t4 +
      where t1.partno=t2.partno from t1,t2

Under the new restriction of 1024 characters, the same thing can be
accomplished with the following single SELECT statement:

    select * to t4 +
      where t1.partno=t2.partno from +
      (select * to t1 from inventry order by partno), +
      (select distinct partno to t2 from +
      (select partno order by partno +
      where t3.suppno=quotatns.suppno from quotatns, +
      (select suppno to t3 from supplier where name='atlantis co.')))


the results are as follows:

                   1         2         3         4         5
          123456789012345678901234567890123456789012345678901234567

                                                                ×T4
      DBD ×PARTNO×DESCRIPT $×QONHAND×
      001 222    BOLT       1250
      002 232    NUT        1100
      003 241    WASHER     6000

UPDATE SUBCOMMAND - ALTERING DATA                                      @

You can also make changes to a table.  Suppose 200 parts with part
number 221 have just been delivered to your warehouse.  The
following subcommand will update the database:

  update inventry set qonhand=qonhand+200 where partno=221

The UPDATE subcommand is not limited to a single value or row of
values:

  update quotatns set deliv=deliv+7, suppno=suppno+100

SEQ - A SPECIAL FIELD NAME                                             @

The field name SEQ is special.  If you have not given the name SEQ
to any field, yet you reference it in any expression either in the
select-list or in the where-clause, the sequence number of the
current record will be referenced.  For example, to select every
third record from a file sequence numbered beginning with 1,
incremented by 1, enter "select * where mod(seq,3)=0".

BACKUS-NAUR DEFINITION OF SYNTAX                                       @

For those reading this who are heavy into computer science, a
normal syntactical definition of the RQL language may be useful.
if you don't recognize the names Backus and Naur, don't bother
reading this section.

In the following Backus-Naur statements, a phrase such as "<1,
<expression> / ','>" signifies the appearance of one or more
expressions, separated by commas.  A phrase such as "<name-reference>
"'NOT') 'LIKE'" implies that the keyword 'NOT' is optional.  Also,
some definitions were simple enough that a formal definition wasn't
considered necessary, and an example was given instead.  For example,
"<name> e.g. abc123" is given instead of a formal definition of
names. Other than that, the format is essentially pure Backus-Naur:

<locate> ::= 'LOCATE' ('NEXT') <where-clause>

<remove> ::= 'REMOVE' <where-clause>

<sort> ::= 'ORDER' 'BY' <seq-spec>

<update> ::= 'UPDATE' (<name>)
             'SET' <1, <name> '=' <expression> / ','>
             (<where-clause>)

<query> ::= 'SELECT' <select-clause> <0, <other-clauses>>

<other-clauses> ::= <from-clause> ×
                    <where-clause> ×
                    <group-by-clause> ×
                    <order-by-clause> ×
                    <to-clause> ×
                    <drop-clause> ×
                    <rename-clause>

<select-clause> ::= '*' ×
                    ('ALL' × 'DISTINCT') <select-list>

<select-list> ::= <1, <select-list-element> / ','> ×
                  <1, <summary-element> / ','> ×
                  <summary-function-name>

<select-list-element> ::= <expression> × <list-query> × <character>

<summary-element> ::= <summary-function-reference> × <name-reference>

<from-clause> ::= 'FROM' <1, <from-spec> / ','>

<from-spec> ::= <name> ('-' <name>) × '(' <query> ')'

<where-clause> ::= 'WHERE' <search-condition>

<group-by-clause> ::=
    'GROUP' ('BY') <seq-spec>

<search-condition> ::= <expression> ×
                       <name-reference> 'LIKE' <character> ×
                       <name-reference> 'IN' <list>

<list> ::= '(' <1, <expression> / ','> ')'

<order-by-clause> ::= <order-spec> ('BY' <seq-spec>)

<order-spec> ::= 'ORDER' × 'MERGE' × 'SET' × 'UPDATE'

<seq-spec> ::=  <1 <name> ('ASC'×'DESC') / ','>

<to-clause> ::= 'TO' <name>

<drop-clause> ::= 'DROP' <1, <name> / ','>

<rename-clause> ::= 'RENAME' <1, <rename> / ','>

<rename> ::= <oldname> '=' <newname>

<oldname> ::= <name>

<newname> ::= <name>

<expression> ::=  ('(') <express> (')')

<express> ::= <1, <orterm> / '×' × 'OR'>

<orterm> ::= <1, <andterm> / '&' × 'AND'>

<andterm> ::= <1, <relterm> / '<'×'^<'×'<='×'='×'^='×'>='×'>'×'^>' >

<relterm> ::= <1, <addterm> / '+' × '-'>

<addterm> ::= <1, <factor> / '*' × '/'>

<factor> ::= <1, <expterm> / '**'>

<expterm> ::= ('+' × '-' × '^' × 'NOT') <sufterm>

<sufterm> ::= <constant> × <name-reference> ×
              <function-reference> × <assignment>

<assignment> ::= <name> '#' <expression>

<function-reference> ::=
                 <name> '(' <expression> ')'

<summary-function-reference> ::=
                 <summary-function-name> '(' <expression> ')'

<summary-function-name> ::= 'AVG' × 'SUM' × 'MIN' × 'MAX' ×
     'COUNT' × 'STD'

<name-reference> ::= (<name> '.') <name>

<constant> ::= <numeric> ×
               <character>

<numeric> e.g. 123.45

<character> e.g. 'how now brown cow'

<name> e.g. abc123

<list-query> ::= <query>


SAS UNDER ABE                                                          @

ABE has a convenient interface to SAS built into it.  This interface
does special processing for currently edited datasets that have a
view defined.  But first, because the interface is useful even
without this special processing, it will be demonstrated in its
simpler form.

Suppose I edit a set of SAS source statements such as the following,
and enter the SAS subcommand:

            1         2         3         4         5
   12345678901234567890123456789012345678901234567890123456789

   sas                        ×SAMPLE×X75826.SAS.CARDS(SAMPLE)
   001 * DSN=SAS.CARDS(SAMPLE);
   002 OPTIONS LS=70 PS=50;
   003 DATA;
   004   TITLE SAMPLE OF SIMPLE LINEAR REGRESSION;
   005   INPUT X Y;
   006   CARDS;
   007   280 2.1
   008   250 3.0
   009   300 3.2
   010   320 1.4
   011   310 2.6
   012   280 2.9
   013   320 1.3
   014   300 3.4
   015   320 2.8
   016 PROC REG;
   017   MODEL Y=X;

the result will be the following display:

            1         2         3         4         5
   12345678901234567890123456789012345678901234567890123456789

                                         ×LIST×X75826.SAS.LIST
   001 1SAMPLE OF SIMPLE LINEAR REGRESSION
   002
   003
   004  DEP VARIABLE: Y
   005 0                 SUM OF       MEAN
   006  SOURCE    DF    SQUARES     SQUARE      F VALUE       PROB>F
   007 0MODEL      1   0.886678   0.886678        1.665       0.2380
   008  ERROR      7   3.728878   0.532697
   009  C TOTAL    8   4.615556
   010 0    ROOT MSE   0.729861   R-SQUARE       0.1921
   011      DEP MEAN   2.522222   ADJ R-SQ       0.0767
   012      C.V.       28.93721
   013 0
   014                PARAMETER   STANDARD   T FOR H0:
   015  VARIABLE  DF   ESTIMATE      ERROR  PARAMETER=0   PROB > ×T×
   016
   017  INTERCEP   1   6.676585   3.229221        2.068       0.0775
   018  X          1  -0.013951   0.010814       -1.290       0.2380

The above is the edited output resulting from invoking the %SAS
procedure passing the SAMPLE source statements shown above as input.
the source is first written to data set LASTJCL.CNTL (which will
be created if it doesn't currently exist), and LASTJCL.CNTL is
passed to the %SAS procedure via the DATASET (DA for short)
keyword.

Several points need to be made about the SAS subcommand:

  1.  You can enter any of the keywords you might normally use
      when specifying the %SAS command in READY mode, except the
      OUTPUT and LOG keywords.

  2.  ABE uses the OUTPUT and LOG keywords to divert the output from
      SAS to data sets SAS.LOG and SAS.LIST.  If either of these
      data sets doesn't exist when the SAS subcommand is issued,
      ABE will create them for you with attributes DCB=(LRECL=169,
      BLKSIZE=19000,RECFM=VBA),SPACE=(TRK,(5,1)).

  3.  After SAS has been invoked, you will receive control back at
      the terminal with all of your original data sets still being
      edited, plus SAS.LOG and SAS.LIST, which will be designated
      symbolic names LOG and LIST, respectively.

  4.  It is important that you not use the symbolic names LOG and
      LIST on any data sets other than SAS.LOG and SAS.LIST.  If
      you do, your data sets won't be damaged, but when you
      receive control, the LOG and LIST data sets won't be
      available.

  5.  Both the LOG and LIST data sets will be defined as SUPPORT
      data sets.  For details, see HELP data for the SUPPORT
      subcommand, but briefly, SUPPORT data sets will not show on
      the display in response to a LINES subcommand, and if you
      end editing of any data set on the display, if the only data
      sets then being edited are SUPPORT data sets, editing will
      be ended (with "end nosave" subcommands) for all of them and
      you will be returned to READY mode.

  6.  One extra keyword can be specified on the SAS subcommand,
      namely the NOGO keyword.  Normally, the second and subsequent
      times you issue the SAS subcommand in a given ABE session,
      %SAS will be invoked with the GO keyword, unless you
      specify NOGO.

Continuing on with the sample, suppose I next enter the subcommand
"show log".  The result would be the following display:

            1         2         3         4         5
   12345678901234567890123456789012345678901234567890123456789

                                         ×LIST×X75826.SAS.LIST

   001 1        S A S   L O G    OS SAS 82.2B  VS2/MVS TSO USER X758
   002 0NOTE: SAS RELEASE 82.2B AT KIMBERLY-CLARK CORPORATION (01641
   003 0NOTE: CPUID   VERSION = 00  SERIAL = 021957  MODEL = 3033 .
   004   17 * DSN=SAS.CARDS(SAMPLE);
   005   18 OPTIONS LS=70 PS=50;
   006   19 DATA;
   007   20   TITLE SAMPLE OF SIMPLE LINEAR REGRESSION;
   008   21   INPUT X Y;
   009   22   CARDS;
   010  NOTE: DATA SET WORK.DATA2 HAS 9 OBSERVATIONS AND 2 VARIABLES
   011  TRK
   012
   013   32 PROC REG;
   014   33   MODEL Y=X;
   015
   016 0NOTE: SAS INSTITUTE, SAS CIRCLE, BOX 8000, CARY, N.C. 27511-




SAS UNDER ABE - HOW DATASETS WITH VIEWS ARE HANDLED                    @

Whenever you issue the SAS subcommand, ABE performs some special
processing for every data set currently being edited that has a
view defined over it.  What it amounts to is that you may depend
on the SAS WORK data set containing up-to-date copies of all
such data sets.

For example, if I were currently editing the data set INVENTRY
previously described under the heading "SAMPLE DATA SETS FOR FURTHER
EXAMPLES", I could enter the subcommand sequence -

    *define xxx*a xxx nl proc means data=inventry;*a xxx sas

this would:  (1) create a new data set called XXX; (2) add a single
line to it containing "proc means data=inventry;"; (3) invoke SAS
to execute the given statement.  The results would be the
following:

                  1         2         3         4         5         6
         123456789012345678901234567890123456789012345678901234567890
                                                ×LIST×X75826.SAS.LIST
     001 1
     002
     003  VARIABLE   N   MEAN    STANDARD   MINIMUM MAXIMUM STD ERROR
     004                         DEVIATION   VALUE   VALUE   OF MEAN
     005
     006  PARTNO     9   238.11    31.4223  207.00   295.00  10.47
     007  QONHAND    9  1140.00  1875.0483   50.00  6000.00 625.01

The maintenance of the data set copies in the SAS WORK library is
done as efficiently as possible.  That is, if I subsequently
invoke SAS with the statements -

     PROC REG DATA=INVENTRY; MODEL PARTNO=QONHAND;

Unless I have altered the INVENTRY data set under ABE, it won't
have to be re-written to the SAS WORK library; this is done only
when necessary, and I don't have to worry about it.

Of course, if you intend to invoke SAS via the SAS subcommand of
ABE, don't have views defined over any unnecessary data sets,
especially if they are large ones.  It won't hurt anything if
you do, but it will cause some unnecessary overhead.




USE SUBCOMMAND - MORE DETAILED INFORMATION                             @

As already indicated, the USE subcommand is used to define the name,
position, length, and data type of all fields defined over a data set.
So far, the only two data types introduced have been zoned decimal and
character.  Other data types which may be specified are packed decimal,
fixed binary, and floating point (see also the section in this
Appendix titled "USING OTHER DATA FORMATS - PACKED, FIXED, FLOAT,
ETC.").

Of the data types which may be used, only zoned decimal and character
data are directly printable on the display screen.  Either the data
must be displayed in an indirect format called printable, or external,
hexadecimal, or the data must be converted to zoned decimal before
being displayed.  The USE subcommand allows you to control which form
is used by allowing you to define two distinct but concurrently
existent views of the data; the data view and the display view.

The data view describes the actual position, length, and data type of
each field in the dataset.  The display view describes which fields
from each record are to be displayed, and describes the location on
the screen where each field is to be displayed, the number of
characters to be printed, and whether or not the field is to be
converted to zoned decimal for printing.

When the following syntactical forms of the USE subcommand are used,
the data view will be defined:

 use <form-spec>
  or
 use input <field-specs>
  or
 use fixed <field-specs>

The following syntactical form is used to alter only the display view
without changing the data view:

 use display <display-field-specs>

When a display view is defined for a dataset, the image you see of
each record on the screen is artificial.  Whereas the data view may
define the datatype for a given field to be packed decimal, the
display view will cause this field to be displayed in zoned decimal.
normally, this artifical view is more desireable, since printable
hexadecimal is more difficult to interpret than zoned decimal, e.g.
"-7" is more understandable than "FFFFFFF9", both of which represent
the value which might be stored in a fullword fixed binary data field.
However, if you wish to view the data in hexadecimal, you may do so
by entering the USE subcommand in the following format, thereby
eliminating the display view altogether:

  use nodisplay

Other syntactical forms of the USE subcommand which will be explained
somewhere in this appendix follows:

 use list
  or
 use set
  or
 use nosym
  or
 use in
  or
 use out

The functions the USE subcommand performs can be broken up into several
categories, depending on which keyword is used:

  Category 1:  The USE subcommand is used to create or change a data
               view of the data set; that is, the fields that are
               defined over the data set, and where they are located
               in each record.  Fields may be fixed or free-form, or
               in other words, their positions and lengths may be
               fixed and remain static (fixed), or their positions
               and lengths may vary depending on the format of the
               current record (free-form).  The pertinent keywords
               are IN, OUT, FIXED, and INPUT.  More details will be
               given about the differences between the FIXED and
               INPUT keywords later on.  For more information on the
               IN OUT keywords, see the section titled "STORING
               DATABASE VIEWS WITH THE DATASET."

  Category 2:  The USE subcommand is issued to establish free-form
               field positions and lengths based on data in the
               current record, and also possibly to extract data
               from the current record.  The pertinent keywords are
               SET and NOSYM.  Both SET and NOSYM request that
               free-form field positions and lengths be determined.
               If set is used, however, the additional function is
               performed of extracting data from the current record
               These functions are described in more detail later on.

  Category 3:  There are two keywords for this category, namely
               LIST, which requests a list of the current view with
               with names in record position sequence,
               and LISTAVL, whic requests a list of the current
               view with field names in alphabetic collating sequence.
               All field names are listed, along with their
               positions and lengths.  If a field is free-form, its
               position and length specifications will be listed as
               0.

  Category 4:  The USE subcommand is used to create or change a
               display view of the data set; that is, the description
               of how the data in each record is to be displayed for
               editing.  See the section titled "DISPLAY VIEWS AND
               THE USE SUBCOMMAND."

FIELD SPECIFICATIONS - FIXED FORMAT                                    @

<field-specs> (field specifications) are perhaps more easily
understood by illustration than by a rigorous and formal
description of the syntax.  Suppose the current record in the
data set appears as follows:

                1         2         3         4
       1234567890123456789012345678901234567890

    10 23       57   84   92

When the subcommand "use fixed x y z" followed by the subcommand
"use list" would produce the following listing at the terminal:

    FIELD NAME=X      OFFSET=   1 LENGTH=    9
    FIELD NAME=Y      OFFSET=  10 LENGTH=    5
    FIELD NAME=Z      OFFSET=  15 LENGTH=    5

If the subcommand "use set" is then entered followed by the
subcommand "r nl &z&y&x" then the data set will appear as
follows:

                1         2         3         4
       1234567890123456789012345678901234567890

   DBD ×X       ×Y   ×Z   ×
   010 23       57   84   92
   011 84   57   23

First note the appearance of the line beginning "DBD" on the
display.  This will appear at the top of any data set which
currently has a database definition associated with it.  As
you will see later on, you can modify the database definition
without having to enter another USE subcommand simply by
altering this line on the display.)

Suppose "use fixed x 10-15 y 1-5 z 20-23" had been entered
followed by "use list".  The resulting list will appear as
follows:

    FIELD NAME=X      OFFSET=  10 LENGTH=    6
    FIELD NAME=Y      OFFSET=   1 LENGTH=    5
    FIELD NAME=Z      OFFSET=  20 LENGTH=    4

If the subcommands "use set" followed by "r nl &z&y&x" were
when entered, the result would be the following:

                1         2         3         4
       1234567890123456789012345678901234567890

   DBD ×Y       ×X        ×Z
   010 23       57   84   92
   011 92  23   57   8

Suppose "use fixed a 1 b 5-10 c d" had been  entered followed by
"use list".  The resulting list would be:

    FIELD NAME=A      OFFSET=   1 LENGTH=    1
    FIELD NAME=B      OFFSET=   5 LENGTH=    6
    FIELD NAME=C      OFFSET=  11 LENGTH=    4
    FIELD NAME=D      OFFSET=  15 LENGTH=    5

FIELD SPECIFICATIONS - FREE-FORM                                       @


The above examples all illustrate how the USE subcommand works
when the keyword "fixed" is specified.  The position of each
named field is fixed based either on the column field
specifications in the subcommand (e.g. use fixed x 1-5) or
if those specifications are omitted (e.g. use fixed x y),
they are based on the format of the data in the current
record in the data set as follows:

During the field definition process, a program variable named
CURSOR is maintained.  When a field has been defined, CURSOR
will contain the position of the next character beyond that
field.  For example, if field ABC has just been defined to be
in columns 10 thru 15, CURSOR will contain 16.  If the next
field named on the USE subcommand doesn't have a column field
specification associated with it, e.g. use input abc 10-15 x y,
when the field position and length will be derived from the
data format in the current record, and from the CURSOR variable
as follows:

Suppose the current record looks like the following, and that
CURSOR currently contains 16, and that field named x is currently
being defined:

              1         2         3         4
     1234567890123456789012345678901234567890

  10 23       57   84   92

First, the starting position of field named x is defined to be
the current value of CURSOR.  In this example, that would be
position 16.  Next the data in the current record is examined at
position 16 to determine the field length.  Data in each field is
assumed to be left-justified, so the CURSOR is then moved to the
first blank character starting at position 16 (16 being the
current value of CURSOR).  In this case, CURSOR will be set to
17. CURSOR is then moved to the next non-blank character in the
record, which is assumed to be the first character of the next
field beyond the one currently being defined.  In this case,
CURSOR would equal 20.  Subtracting the current CURSOR value, 20,
from the original CURSOR value, 16, produces a field length for
field x to be 4.

As mentioned previously, the "fixed" keyword causes the position
and length of each field specified to be fixed at the time of the
execution of the USE subcommand.  If the "input" keyword is used
instead, however, it is possible to process data in which the
fields are not at fixed locations in each record.  For example,
suppose the current data set contained the following three
records:

              1         2         3         4
     1234567890123456789012345678901234567890

  10 23       57   84   92
  20 92  23   57   8
  30 84   57   23

Then suppose the following RUN were executed:

  A XXX END N
  DEFINE XXX
  USE INPUT X Y Z
  SETL LNO 0
  $ LOOP
  INCR LNO 10
  $IF &LNO > 00030 EOJ
  V &LNO
  USE SET
  A XXX NL &Z &Y &X
  $GOTO LOOP

The result in data set named XXX would be as follows:

              1         2         3         4
     1234567890123456789012345678901234567890
                                        ×XXX×
 DBD ×(X Y Z)
 001 84 57 23
 002 57 23 92
 002 23 57 84

(Note the format of the DBD line.  This is how a series of
free-form fields will be represented.)

As you can see, the position of fields x, y, and z varied from
record to record, and was based on the position of non-blank
data in each record.

Note that fixed- and free-form can be mixed, e.g.
"use input x y 10-15 z".  In this example: Field x would begin
with the first non-blank character in each record, and would
and at the next blank; Field y would always be in columns 10
thru 15; Field z would begin with the first non-blank character
beyond column 15, and would end at the next blank after that.

USE SUBCOMMAND - NAME RESTRICTION                                      @

The USE subcommand will not accept duplicate field names, and will
terminate with an error message if one is encountered.

USING SELECT WITH FREE-FORM FIELDS                                     @

The simplest SELECT subcommand to enter is "select *".  This will
copy all fields in all records to a new virtual data set. If
all fields are defined to be fixed in format (no free-form
fields), the "select *" would operate similar to the DREM subcommand.
however, if the DBD contains free-form fields, the results of a
"select *" are shown below:


              1         2         3         4
     1234567890123456789012345678901234567890
 select * to yyy                       ×XXX×
 DBD ×(A B C)
 010 23       57   84   92
 020 92  23   57   8
 030 84   57   23

the above would produce the following new data set as a result:

              1         2         3         4
     1234567890123456789012345678901234567890
                                        ×YYY×
 DBD ×(A B C)
 001 84 57 23
 002 57 23 92
 002 23 57 84

As you can see, all the extraneous blanks have been removed, and
only the information for fields A, B, and C were copied.

Note that use if free-form fields is not permitted with the UPDATE
subcommand.  Also, there are restrictions on the use of free-form
fields with the SELECT subcommand; The MERGE and UPDATE
keywords are not permitted with free-form fields.

USING OTHER DATA FORMATS - PACKED, FIXED, FLOAT, ETC.                  @

So far, only character and printable-numeric (zoned decimal) data
formats have been shown.  You can define fields with the USE
subcommand having other data formats, such as packed decimal,
floating point, and printable hexadecimal. For example,

  USE FIXED NAME $ 1-8 @ 9 PARTNO PD7. @ 16 COST RB8.

The above subcommand defines a view of a data set with character data
in columns 1-8, packed decimal data in column 9-15, and floating
point data in columns 16-23.  Note the syntax for defining the
new formats is different.  If you are familiar with SAS, you will
recognize it as the formatted input type.  For a given field,
you start with and "@" character, followed by by the field name,
followed by the field format identification, with the field
length appended to it, terminating with a period.

All of the possible data formats available are:

    FORMAT    DESCRIPTION            LENGTH RESTRICTIONS

    $CHARn. - character              maximum length = 256
    HEXn.   - printable hexadecimal  maximum length = 256
    IBn.    - integer binary         length = 2 or 4
    PIBn.   - bit                    maximum length = 256
    PDn.    - packed decimal         maximum length = 8
    RBn.    - floating point         length = 4 or 8 or 16

Note that variables with different data formats can be used in the
same expression.

DISPLAY VIEWS AND THE USE SUBCOMMAND                                   @

Be sure you've read the section title "THE USE SUBCOMMAND - MORE
DETAILED INFORMATION" before reading this section.  To change the
display view for a dataset without modifying the data view, the
syntax is -

  use display <display-field-specs>

Format 1:  use display
  Use display with no operands indicates this subcommand is to derive
  the display view from the data view determining the lengths to be
  displayed on its own.

Format 2:  use display × name1 ×  × name2 × ...
  This format will be transformed into format 1 if "use display ×" is
  specified, and otherwise will be transformed to format 3.

Format 3:  Example follows -
  Use display a 1-1 b 5-10
    field a will begin in column 1, and will be 1 column long.
    field b will begin in column 5, and will be 6 columns long.

Format 4:  use display name1 name2 ...
  The data view will be scanned, and for each name specified on the
  format 2 use display subcommand the appropriate description will be
  added to the display view.

ENTER SUBCOMMAND - BULK DATA ENTRY                                     @

The ENTER subcommand will be useful on those occasions when you have
large numbers of records to add to a data set. For
example, suppose I wish to add 5 records to the SUPPLIER file.
to do so, I enter the ENTER subcommand on the command line for
the SUPPLIER file:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      enter                                                 ×SUPPLIER
      DBD ×SUPPNO×NAME $         ×ADDRESS $                       ×
      001 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      002 52     VESUVIUS, INC.  312 ANCIENT BLVD., POMPEII NY
      003 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC
      004 54     TITANIC PARTS   32 LARGE ST., BIGTOWN TX
      005 57     EAGLE HARDWARE  64 TRANQUILITY PLACE, APOLLO MN
      006 61     SKY PARTS       128 ORBIT BLVD., SIDNEY AUSTRALIA
      007 64     KNIGHT LTD.     256 ARTHUR COURT, CAMELOT ENGLAND

The display will then be cleared, and the following title line
will be displayed:

      SUPPNO NAME             ADDRESS

Each line after the title line will have three input fields defined,
and I can use the physical tab key to skip from one field to the
next.  Suppose I key in the following three lines of data and press
enter (note that only three lines were entered for illustration
purposes, but more could have been keyed in before pressing enter;
up to 42 lines of data on a 43*80 screen size):

      SUPPNO NAME             ADDRESS
      1      tom              306 author st, edittown, wis.
      2      mary             104 muddy road, unclear, ind.
      3      sam              cozy nook, feline, n.y.

The display will once again be cleared, and the title line will
reappear.  I can then fill up the screen with more data lines.
this cycle will continue until I press any one of the program
function keys instead of the ENTER key.  Suppose I key in two
more data lines, and press PFK 1:

      SUPPNO NAME             ADDRESS
      4      muffin           gruff lane, scruffy, ill.
      5      glen             taciturn ave. quiet, neb.

the resulting display will be as follows:

                   1         2         3         4         5
          12345678901234567890123456789012345678901234567890123456789

      enter                                                 ×SUPPLIER
      DBD ×SUPPNO×NAME $         ×ADDRESS $                       ×
      001 51     DEFECTO PARTS.  16 BUM ST., BROKEN HAND WY
      002 52     VESUVIUS, INC.  312 ANCIENT BLVD., POMPEII NY
      003 53     ATLANTIS CO.    8 OCEAN AVE., WASHINGTON DC
      004 54     TITANIC PARTS   32 LARGE ST., BIGTOWN TX
      005 57     EAGLE HARDWARE  64 TRANQUILITY PLACE, APOLLO MN
      006 61     SKY PARTS       128 ORBIT BLVD., SIDNEY AUSTRALIA
      007 64     KNIGHT LTD.     256 ARTHUR COURT, CAMELOT ENGLAND
      008 1      TOM             306 AUTHOR ST, EDITTOWN, WIS.
      009 2      MARY            104 MUDDY ROAD, UNCLEAR, IND.
      010 3      SAM             COZY NOOK, FELINE, N.Y.
      011 4      MUFFIN          GRUFF LANE, SCRUFFY, ILL.
      012 5      GLEN            TACITURN AVE. QUIET, NEB.

ENTER SUBCOMMAND - FIELD NAME RESTRICTION                              @

The ENTER subcommand will not accept a field name beginning with the
character "z" and will terminate with an error message if one is
encountered.`

DROP CLAUSE - DROPPING VARIABLES                                       @

The following two SELECT subcommands perform identical functions:

   1:  select suppno,partno,deliv,qonorder from quotatns

   2:  select * drop price from quotatns

The drop clause is convenient when you have a data set with a long
list of variables, and you want to select all but a few of them.

LOCATE SUBCOMMAND - FIND OCCURRENCE SATISFYING EXPRESSION              @

The LOCATE subcommand is used to locate the first record in the data
set that satisfies a given WHERE expression, e.g. "locate where
suppno=51 & partno=221" will change the current line pointer to
point to the first record with suppno=51 & partno=221.

If the LOCATE subcommand includes the NEXT keyword, e.g. "locate
next where suppno=51 & partno=221", the search will begin will the
next record following the current one, instead of with the first
record in the data set.

DISPLAY KEYWORD - AUTOMATICALLY CONVERTING TO PRINTABLE DATA           @

Suppose you were editing the following SMF data:

                            1 0                 2 0                 3
          1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0

                                              ×U000×U.SD.U000.SMFDATA
    00010 . ! . . , . . c . . T C M 1 . . . . . . . . . . . . . . . .
    00010 025A00626BBA0083232FE3C3D4F1000000000024000C000100000030001
    00020 . . . . c . . c . . T C M 1 . . . . . . . . . . . . . . . .
    00020 0217006683CE0083232FE3C3D4F100000000002C000C000100000038000
    00030 . . . % . . . c . . T C M 1 . . . . . . . . . . . . . . . .
    00030 0217006C020E0083232FE3C3D4F100000000002C000C000100000038000

Column 2 contains the SMF record type in binary, columns 3 thru 6
contain the time in binary in hundredths of seconds that the record
was created, columns 7 thru 10 contain the julian date in packed
decimal when the record was created, and columns 11 thru 14 contain
the cpuid in printable EBCDIC.

It would be nice to see these fields in printable zoned decimal.
this can be done with the following three ABE subcommands:

  USE FIXED @ 2 TYP PIB1. +
            @ 3 TIM IB4.  +
            @ 7 DAT PD4.  +
            @ 11 CPUID $CHAR4.
  SELECT * TO RESULT DISPLAY
  A DISPLAY CHAR

the results would be as follows:

                                                             ×RESULT××
    DBD ×TYP         ×TIM            ×DAT         ×CPUID $×
  00001 90           6450106         83232        TCM1
  00002 23           6718414         83232        TCM1
  00003 23           7078414         83232        TCM1

The above example introduces the DISPLAY keyword of the SELECT
subcommand.  It tells ABE to convert all fields not already
defined in the TO-data set to zoned decimal when the FROM-field
is numeric, and to expand the length of the field such that there
is room enough to print the full name in the DBD.

Incidentally,  when this example was done in real life, I didn't
like the time displayed in units of hundredths of seconds, so
I entered the following two ABE subcommands:

  UPDATE SET HHMMSS=INT(TIM/360000)*10000 + +
                    INT(MOD(TIM,360000)/6000) + +
                    INT(MOD(TIM,6000)/100)
  AR ALL 56 51

the result was as follows:

                                                             ×RESULT××
    DBD ×TYP         ×TIM            ×DAT         ×CPUID $×HHMMSS    ×
  00001 90           6450106         83232        TCM1    170056
  00002 23           6718414         83232        TCM1    180083
  00003 23           7078414         83232        TCM1    190083

RENAME CLAUSE OF THE SELECT SUBCOMMAND - RENAMING FIELDS               @

Suppose you had the following data set -

                   1         2         3
          12345678901234567890123456789012345678

                                       ×INVENTRY
      DBD ×PARTNO×DESCRIPT $×QONHAND×
      001 207    GEAR          75
      002 209    CAM           50
      003 221    BOLT         650
      004 222    BOLT        1250
      005 231    NUT          700
      006 232    NUT         1100
      007 241    WASHER      6000
      008 285    WHEEL        350
      009 295    BELT          85

and entered the following subcommand -

      SELECT * FROM INVENTRY RENAME PARTNO=NO, +
        DESCRIPT=PART,QONHAND=ONHAND TO XYZ

the result would be the following data set:

                   1         2         3
          12345678901234567890123456789012345678

                                            ×XYZ
      DBD ×NO    ×PART $    ×ONHAND ×
      001 207    GEAR       75
      002 209    CAM        50
      003 221    BOLT       650
      004 222    BOLT       1250
      005 231    NUT        700
      006 232    NUT        1100
      007 241    WASHER     6000
      008 285    WHEEL      350
      009 295    BELT       85

The above example illustrates the use of the RENAME keyword.

VARIABLES AND EXPRESSION IN UPDATE AND SELECT STATEMENTS               @

When a name is used on a SELECT or UPDATE subcommand, if the name
doesn't match a field name in a DBD involved, then ABE will obtain
the value from the symbolic variable pool.  The replacement values
associated with names in the variable pool are set in many ways, e.g.
"calc a#23**2" and "setl b 23.5".  The example below illustrates
referencing values from prior observations to set values in the
current one:

Given the following subcommands:

  DEL
  BL 10
  CALC X1#X2#X3#X4#-1
  UPDATE SET XXXX=(X4#X3),XXX=(X3#X2),XX=(X2#X1),X=(X1#SEQ**2)

The result would be:

                   1         2         3         4
          1234567890123456789012345678901234567890

      DBD ×X        ×XX       ×XXX      ×XXXX    ×
          1         -1        -1        -1
          4         1         -1        -1
          9         4         1         -1
          16        9         4         1
          25        16        9         4
          36        25        16        9
          49        36        25        16
          64        49        36        25
          81        64        49        36
          100       81        64        49

XXXX contains the value of X in the fourth observation prior to the
current, XXX contains the value of in the third observation prior to
the current. etc.
